from jobspy import scrape_jobs
import pandas as pd
import csv

# Step 1: scrape
df = scrape_jobs(
    site_name=["linkedin"],
    search_term="Network Engineer",
    location="Jalisco",
    results_wanted=30,  # you can increase later
    linkedin_fetch_description=True,
)

print("Columns:", df.columns)

# Step 2: define description keywords
keywords = ["vpn", "tcp", "wan", "lan", "ip", "cloud", "vmware", "cisco"]
pattern = "|".join(keywords)

# Step 3: find description column
desc_col = next((c for c in df.columns if "desc" in c.lower()), None)
if not desc_col:
    raise ValueError("No description column found!")

# Step 4: filter by description content
filtered_df = df[df[desc_col].astype(str).str.contains(pattern, case=False, na=False)]

# Step 5: filter by entry-level job level (when available)
if "job_level" in filtered_df.columns:
    entry_keywords = ["entry", "junior", "intern", "graduate", "trainee"]
    filtered_df = filtered_df[
        filtered_df["job_level"].astype(str).str.contains("|".join(entry_keywords), case=False, na=False)
        | filtered_df["title"].astype(str).str.contains("|".join(entry_keywords), case=False, na=False)
    ]

# Step 6: pick link column (LinkedIn has both job_url and job_url_direct)
link_col = "job_url_direct" if "job_url_direct" in df.columns else "job_url"

# Step 7: show only the first few for console readability
pd.set_option("display.max_colwidth", 120)
print(filtered_df[["title", "company", link_col, desc_col]].head())

# Step 8: save to CSV with full description text
filtered_df.to_csv("jobs_filtered_entry_level.csv", index=False, quoting=csv.QUOTE_ALL, encoding="utf-8")

print(f"\nâœ… Saved {len(filtered_df)} filtered entry-level jobs to jobs_filtered_entry_level.csv")
